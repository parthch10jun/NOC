# -*- coding: utf-8 -*-
"""GCRL4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TafzihlvjmLWJkoQt-0rFt3BxBe1tGwa

Application: MPEG Topology : 4_4 Environment : NoCTopology Agent : Cores of the Application Graph States : Router Action : Mapping between Core_Router Policy : Communication Cost Reduction Rewards : Depend upon the Comm. Cost.
"""

pip install torchviz

import math, random, copy
import numpy as np
import pandas
import os 
import torch
import torch.nn as nn
import torch.optim as optim
import torch.autograd as autograd 
import torch.nn.functional as F
from collections import deque 
import random
import copy
Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs)
from google.colab import files  
import io  # Added
from googleapiclient.http import MediaIoBaseDownload  # Added
from torchviz import make_dot
from torchsummary import summary

Application=(input("Enter Name of Application: "))
    No_Cores=int(input("Enter Total No. of Cores in Application Graph: ")) 
    No_Links=int(input("Enter Total No. of Links in Application Graph: ")) 
    col_list = ["Source", "Destination","Bandwidth"]
    filename = input("Enter the path of your file: ")
    uploaded = files.upload()
    #filepath= ('D:\Jitesh\PHD\1_PHD Work\Benchmark_Applications\APP1'+ filename)
    #assert os.path.exists(filepath), "I did not find the file at, "+str(filepath)
    print("Hooray we found your file!")
    Core_Graph = pandas.read_csv(io.BytesIO(uploaded['mpeg.csv']))
    Row= int(input("Enter No. of Mesh Row: "))
    Col= int(input("Enter No. of Mesh Col: "))

def distance_matrix(row,col):
    
    # create the grid
    Router_lables_temp1=[]
    size=row*col
    Dist_Matrix= np.array(np.zeros([size,size]))
    for k in range(size):
            p1="R"+str(k+1)
            Router_lables_temp1.append(p1)
            
    # fill in the grid
    for m in range(size):
        for n in range(size):
            
            hopX =  (int)(m%col)-(int)(n%col)
            if(hopX<0):
                hopX = -hopX
            hopY =  (int)(m/col)-(int)(n/col)
            if(hopY<0):
                hopY = -hopY
            Dist_Matrix[m][n] = hopX + hopY
    ds_Matrix = pandas.DataFrame(Dist_Matrix, columns=Router_lables_temp1, index=Router_lables_temp1)
    ds_Matrix = ds_Matrix.astype('int')
   
    return(Dist_Matrix)




#Define the Weight (Bandwidth) Martix of the Given Communication Graph
#def bandwidth_matrix(Row,Col,Links):

def bandwidth_matrix(Row, Col, num_Links, Core_Graph):
       
        Core_labels_temp1 = []
        bwsize = Row * Col
        for p in range(bwsize):
            p2 = "C" + str(p)
            Core_labels_temp1.append(p2)
            
                       
        bw_matrix = np.zeros((bwsize, bwsize))
        Source = Core_Graph['Source']
        Destination = Core_Graph['Destination']
        Bandwidth = Core_Graph['Bandwidth']
        for i in range (num_Links):
               bw_matrix[Source[i]][Destination[i]] = Bandwidth[i]
            
        BW_Matrix = pandas.DataFrame(bw_matrix, columns = Core_labels_temp1, index = Core_labels_temp1)
        BW_Matrix = BW_Matrix.astype('int')
        return(bw_matrix)

class Encoder(nn.Module):
	def __init__(self, din = 12, hidden_dim = 64):
		super(Encoder, self).__init__()
		self.fc = nn.Linear(din, hidden_dim)

	def forward(self, x):
		embedding = F.relu(self.fc(x))
		return embedding

class AttModel(nn.Module):
	def __init__(self, n_node, din, hidden_dim, dout):
		super(AttModel, self).__init__()
		self.fcv = nn.Linear(din, hidden_dim)
		self.fck = nn.Linear(din, hidden_dim)
		self.fcq = nn.Linear(din, hidden_dim)
		self.fcout = nn.Linear(hidden_dim, dout)

	def forward(self, x, mask):
		v = F.relu(self.fcv(x))
		q = F.relu(self.fcq(x))
		k = F.relu(self.fck(x)).permute(0,2,1)
		att = F.softmax(torch.mul(torch.bmm(q,k), mask) - 9e15*(1 - mask),dim=2)

		out = torch.bmm(att,v)
		out = F.relu(self.fcout(out))
		return out

class Q_Net(nn.Module):
	def __init__(self, hidden_dim, dout):
		super(Q_Net, self).__init__()
		self.fc = nn.Linear(hidden_dim, dout)

	def forward(self, x):
		q = self.fc(x)
		return q

class DGN(nn.Module):
	def __init__(self,n_agent,num_inputs,hidden_dim,num_actions):
		super(DGN, self).__init__()
		
		self.encoder = Encoder(num_inputs,hidden_dim)
		self.att_1 = AttModel(n_agent,hidden_dim,hidden_dim,hidden_dim)
		self.att_2 = AttModel(n_agent,hidden_dim,hidden_dim,hidden_dim)
		self.q_net = Q_Net(hidden_dim,num_actions)
		
	def forward(self, x, mask):
		h1 = self.encoder(x)
		h2 = self.att_1(h1, mask)
		h3 = self.att_2(h2, mask)
		q = self.q_net(h3)
		return q

def is_legal(x,y):
	return (x >= 1) & (x <= 4) & (y >= 1) & (y <= 4)

class Mapping(object):
	def __init__(self, n_agent):
		super(Mapping, self).__init__()
		self.n_agent = n_agent
		self.n_action = 5
		self.capability = 2 * self.n_agent
		self.cost = 0
		self.pcost = 0
		self.cv = 0
		self.reward = 0    
        self.steps = 0
		self.len_obs = 18
		self.maze = self.build_env()
        
		self.ants = []
		for i in range(self.n_agent):
			self.ants.append([np.random.randint(0,4)+1,np.random.randint(0,4)+1])#changed ants function to give correct output
  
        maze_ant = np.zeros((6,6))                                               #created maze_ant here itself
        for index in range(self.n_agent):                                        #need to correct get obs function
            row = self.ants[index][0]                                            #correct ants function
            column = self.ants[index][1]
            while (maze_ant[row][column] == 1):                                  #shouldn't be occupied
                row = np.random.randint(0,4)+1  
                column = np.random.randint(0,4)+1
            maze_ant[row][column] = 1
        
                                                                                 #after we have the maze_ant we need to ->
                                                                                 #recreate the self.ants array so that we can use it in other functions
        self.ants = []
        for row in range(len(maze_ant)):
            for column in range(len(maze_ant[row])):
                if (maze_ant[row][column] == 1)
                    self.ants.append([row, column])
                                                                                 #recreated correct ant function
                                                                                 #we need ant function again and again, 
                                                                                 #so it doesn't suffice if we use it once
                                                                                 #and don't allocate it again
	def reset(self):

		self.maze = self.build_env()
		self.cost = 0
		self.pcost = 0
		self.cv = 0
		self.reward = 0
		self.ants = []
		for i in range(self.n_agent):
			self.ants.append([np.random.randint(0,4)+1,np.random.randint(0,4)+1])   
        
        
        maze_ant = np.zeros((6,6))                                               #changed entire reset function '''
        for index in range(self.n_agent):                                           
            row = self.ants[index][0]                                               
            column = self.ants[index][1]
            while (maze_ant[row][column] == 1):                                     
                row = np.random.randint(0,4)+1  
                column = np.random.randint(0,4)+1
            maze_ant[row][column] = 1
        
                                                                                 #after we have the maze_ant we need to recreate the self.ants
                                                                                 #array so that we can use it in other functions
        self.ants = []
        for row in range(len(maze_ant)):
            for column in range(len(maze_ant[row])):
                if (maze_ant[row][column] == 1)
                    self.ants.append([row, column])

		return self.get_obs(), self.get_adj()

    def build_env(self):

		maze = np.zeros((6,6))
		for i in range(6):
			maze[0][i] = -1
			maze[i][0] = -1
			maze[5][i] = -1
			maze[i][5] = -1

		return maze
                                                                                 #Need to re-create ant function to fit parameters '''
	 def get_obs(self):

		obs = []
		maze_ant = np.zeros((6,6))

        for index in range(self.n_agent):                                        #need to correct get obs function
            row = self.ants[index][0]                                            #correct ants function
            column = self.ants[index][1]
            maze_ant[row][column] = 1                                            #finally allot index, gives correct matrix

		for index in range(self.n_agent):
			h = []
			x = self.ants[index][0]
			y = self.ants[index][1]
			for i in range(5):
				h.append(np.mod(x,2))
				x = int(x/2)
			for i in range(5):
				h.append(np.mod(y,2))
				y = int(y/2)
			x_t = self.ants[index][0]
			y_t = self.ants[index][1]
			for i in range(-1,1):
				for j in range(-1,1):
					h.append(self.maze[x_t+i][y_t+j])

			for i in range(-1,1):
				for j in range(-1,1):
					h.append(maze_ant[x_t+i][y_t+j])

			obs.append(h)

		return obs 

	def get_adj(self):
                                                                            #adjacency matrix is incorrect since it considers
                                                                            #diagonals to be adjacent as well
                                                                            #In our problem, only four elements can be considered as adjacent:"""
                                                                            #up, down, left or right
		adj = np.zeros((1,self.n_agent,self.n_agent))

		maze_ant = np.ones((6,6), dtype = np.int)*-1                        #need to correct adj function '''
		for index in range(self.n_agent):
            row = self.ants[index][0]
            column = self.ants[index][1]
            maze_ant[row][column] = index                                   #correctly marking the nodes now

		for index in range(12):
            x = ants[index][0]
            y = ants[index][1]
            for i in range(-1,2):
                if (i != 0):
                    if is_legal(x + i, y):
                        if (maze_ant[x+i][y] != -1):
                            adj[0][index][maze_ant[x+i][y]] = 1
            for j in range(-1,2):
                if (j != 0):
                    if is_legal(x, y + j):            
                        if (maze_ant[x][y + j] != -1):
                            adj[0][index][maze_ant[x][y+j]] = 1

		return adj


	def step(self,actions):
        maze_ant = np.zeros((6,6))

        for index in range(self.n_agent):                                   #added the grid so we don't step on existing grids
            row = self.ants[index][0]                                               
            column = self.ants[index][1]
            maze_ant[row][column] = 1 
        
       
        for i in range(6):                                                  #only considering func maze won't suffice since
                                                                            #it doesn't show current location of core
			maze_ant[0][i] = -1
			maze_ant[i][0] = -1
			maze_ant[5][i] = -1
			maze_ant[i][5] = -1
		
		for i in range(self.n_agent):
			x = self.ants[i][0]
			y = self.ants[i][1]
			
			
			if actions[i] == 0:
				if self.maze[x - 1][y] != -1: 
                    if self.maze[x - 1][y] != 1:
                        self.ants[i][0] = x-1                                
                                                       
			if actions[i] == 1:
				if self.maze[x + 1][y] != -1:
                    if self.maze[x + 1][y] != 1:
                        self.ants[i][0] = x+1
					 
			if actions[i] == 2:
				if self.maze[x][y - 1] != -1:
                    if self.maze[x][y - 1] != 1:
                        self.ants[i][1] = y - 1
					 
			if actions[i] == 3:
				if self.maze[x][y + 1]!= -1:
                    if self.maze[x][y + 1] != 1:
                        self.ants[i][1] = y + 1                            #should we even worry about swapping? 
			
            if actions[i] == 4:
                pass

		self.cost = 0
		self.reward = 0
		for i in range(self.n_agent):
			for j in range(i + 1, self.n_agent):
            # Find Manhattan distance
            # using the formula
            # |x1 - x2| + |y1 - y2|
				Dist = (abs(self.ants[i][0] - self.ants[j][0]) + abs(self.ants[i][1] - self.ants[j][1]))
				bw = bw_matrix[i,j]
				self.cost +=(Dist*bw)
				print(Dist, bw, self.cost)    
				
		if (self.cv==0):
			self.pcost=self.cost
		self.cv +=1
    
		#reward = 1       		
		reward = [1]*self.n_agent
		for i in range(self.n_agent):
			if self.cost < self.pcost:
				self.pcost=self.cost
				reward[i] = 1

		done = False

		if (self.maze.sum()+120) > self.capability:

			return self.get_obs(), self.get_adj(), reward, done, self.ants, self.cost


		return self.get_obs(), self.get_adj(), reward, done, self.ants, self.cost
    
class ReplayBuffer(object):

	def __init__(self, buffer_size):
		self.buffer_size = buffer_size
		self.num_experiences = 0
		self.buffer = deque()

	def getBatch(self, batch_size):
		if self.num_experiences < batch_size:
			return random.sample(self.buffer, self.num_experiences)
		else:
			return random.sample(self.buffer, batch_size)

	def add(self, obs, action, reward, new_obs, matrix, next_matrix, done):
		experience = (obs, action, reward, new_obs, matrix, next_matrix, done)
		if self.num_experiences < self.buffer_size:
			self.buffer.append(experience)
			self.num_experiences += 1
		else:
			self.buffer.popleft()
			self.buffer.append(experience)

#Main_Function

hidden_dim =  64 # 128
max_step = 10
GAMMA = 0.99
n_episode = 20 #1000000
i_episode = 10
capacity = 10000
batch_size = 4 #128
n_epoch = 50
epsilon = 0.9
score = 0
cost=0
cv=0

env = Mapping(n_agent = 12)     #env is the mapping
n_ant = env.n_agent             
observation_space = env.len_obs
n_actions = env.n_action        #nactions is 5 here, up, down, left, right, stay!

buff = ReplayBuffer(capacity)
model = DGN(n_ant,observation_space,hidden_dim,n_actions)
model_tar = DGN(n_ant,observation_space,hidden_dim,n_actions)
optimizer = optim.Adam(model.parameters(), lr = 0.0001)

O = np.ones((batch_size,n_ant,observation_space))
Next_O = np.ones((batch_size,n_ant,observation_space))
Matrix = np.ones((batch_size,n_ant,n_ant))
Next_Matrix = np.ones((batch_size,n_ant,n_ant))

Dist_Matrix = distance_matrix(Row,Col)
bw_matrix = bandwidth_matrix(Row,Col,No_Links,Core_Graph)

#print(Dist_Matrix)
#print(bw_matrix)

print(model)

while i_episode<n_episode:

	if i_episode > 100:
		epsilon -= 0.0004
		if epsilon < 0.1:
			epsilon = 0.1
	i_episode+=1
	steps = 0
	obs, adj = env.reset()
	#print ("obs:",obs)
	#print ("adj:",adj)
  

	while steps < max_step:
		steps+=1 
		action=[]
		q = model(torch.Tensor(np.array([obs])), torch.Tensor(adj))[0]
		for i in range(n_ant):
			if np.random.rand() < epsilon:
				a = np.random.randint(n_actions)
			else:
				a = q[i].argmax().item()
			action.append(a)
			  
		cost = 0 
		next_obs, next_adj, reward, terminated, ants, cost = env.step(action)
		buff.add(np.array(obs),action,reward,np.array(next_obs),adj,next_adj,terminated)
		obs = next_obs
		adj = next_adj
		#score += sum(reward)

	if i_episode < 10:
		continue

	for e in range(n_epoch):
		
		batch = buff.getBatch(batch_size)
		for j in range(batch_size):
			sample = batch[j]
			O[j] = sample[0]
			Next_O[j] = sample[3]
			Matrix[j] = sample[4]
			Next_Matrix[j] = sample[5]

		q_values = model(torch.Tensor(O), torch.Tensor(Matrix))
		target_q_values = model_tar(torch.Tensor(Next_O), torch.Tensor(Next_Matrix)).max(dim = 2)[0]
		target_q_values = np.array(target_q_values.cpu().data)
		expected_q = np.array(q_values.cpu().data)
		
		for j in range(batch_size):
			sample = batch[j]
			for i in range(n_ant):
				expected_q[j][i][sample[1][i]] = sample[2][i] + (1-sample[6])*GAMMA*target_q_values[j][i]
		
		loss = (q_values - torch.Tensor(expected_q)).pow(2).mean()
  
		optimizer.zero_grad()
		loss.backward()
		optimizer.step()

	if i_episode%5 == 0:
		model_tar.load_state_dict(model.state_dict())

#print(adj)
print (ants)
print (cost)